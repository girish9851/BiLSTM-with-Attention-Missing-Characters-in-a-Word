{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T09:10:43.790012Z",
     "iopub.status.busy": "2024-06-23T09:10:43.789261Z",
     "iopub.status.idle": "2024-06-23T09:10:43.801046Z",
     "shell.execute_reply": "2024-06-23T09:10:43.799962Z",
     "shell.execute_reply.started": "2024-06-23T09:10:43.789980Z"
    },
    "id": "sb0zW1T7DIGh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.listdir('../input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T09:11:52.625899Z",
     "iopub.status.busy": "2024-06-23T09:11:52.625543Z",
     "iopub.status.idle": "2024-06-23T09:11:52.675019Z",
     "shell.execute_reply": "2024-06-23T09:11:52.674146Z",
     "shell.execute_reply.started": "2024-06-23T09:11:52.625869Z"
    },
    "id": "U4mKEJSODK3p"
   },
   "outputs": [],
   "source": [
    "### read words ###\n",
    "text_file = open('../input/input-data/words_250000_train.txt',\"r\")\n",
    "full_dictionary = text_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T09:11:56.384018Z",
     "iopub.status.busy": "2024-06-23T09:11:56.383696Z",
     "iopub.status.idle": "2024-06-23T09:12:40.790223Z",
     "shell.execute_reply": "2024-06-23T09:12:40.789236Z",
     "shell.execute_reply.started": "2024-06-23T09:11:56.383993Z"
    },
    "id": "uBBtPhXtrc6Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 09:11:58.030390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-23 09:11:58.030517: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-23 09:11:58.155272: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random.seed(40)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(40)\n",
    "\n",
    "# Sample data for demonstration\n",
    "words = full_dictionary\n",
    "\n",
    "def generate_training_data_3(words):\n",
    "    X = []\n",
    "    y = []\n",
    "    for word in words:\n",
    "      # print(word)\n",
    "      for char in np.unique(list(word)):\n",
    "          X.append(word.replace(char,\"_\"))  # Input with missing character\n",
    "          y.append(char)\n",
    "          try:\n",
    "            X.append(word.replace(char,\"_\").replace(random.choice(list(word.replace(char,\"\"))),\"_\"))  # Input with missing character\n",
    "            y.append(char)                      # Target character (the missing one)\n",
    "          except:\n",
    "            pass\n",
    "          # print(word.replace(char,\"_\"))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Toy dataset\n",
    "X_train_3, y_train_3 = generate_training_data_3(words)\n",
    "\n",
    "words_3 = X_train_3\n",
    "labels_3 = y_train_3\n",
    "\n",
    "max_length_3 = max(len(word) for word in words_3)\n",
    "\n",
    "# Create a dictionary for character to index mapping\n",
    "char_to_index = {char: idx for idx, char in enumerate(set(''.join(words_3)))}\n",
    "index_to_char = {idx: char for char, idx in char_to_index.items()}\n",
    "\n",
    "# Convert words and labels to numerical format\n",
    "X_padded_3 = pad_sequences([[char_to_index[char] for char in word] for word in words_3], maxlen=max_length_3, padding='post')\n",
    "y_padded_3 = np.array([char_to_index[label] for label in labels_3])\n",
    "\n",
    "X_train_3, X_temp_3, y_train_3, y_temp_3 = train_test_split(X_padded_3, y_padded_3, test_size=0.3, random_state=42)\n",
    "X_val_3, X_test_3, y_val_3, y_test_3 = train_test_split(X_temp_3, y_temp_3, test_size=0.5, random_state=42)\n",
    "\n",
    "# print(\"Padded data:\")\n",
    "# for i in range(len(words)):\n",
    "#     print(f\"{words[i]} -> {labels[i]}\")\n",
    "\n",
    "# print(\"\\nPadded and numerical data:\")\n",
    "# print(X_padded_2)\n",
    "# print(y_padded_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T18:25:02.064844Z",
     "iopub.status.busy": "2024-06-20T18:25:02.063934Z",
     "iopub.status.idle": "2024-06-20T18:25:02.070731Z",
     "shell.execute_reply": "2024-06-20T18:25:02.069350Z",
     "shell.execute_reply.started": "2024-06-20T18:25:02.064810Z"
    }
   },
   "source": [
    "# BiLSTM with attention\n",
    "\n",
    "## attention \n",
    "\n",
    "## LSTM 256\n",
    "\n",
    "## embedding - 50\n",
    "\n",
    "## no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T09:12:40.792389Z",
     "iopub.status.busy": "2024-06-23T09:12:40.791843Z",
     "iopub.status.idle": "2024-06-23T09:12:40.799039Z",
     "shell.execute_reply": "2024-06-23T09:12:40.798267Z",
     "shell.execute_reply.started": "2024-06-23T09:12:40.792361Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a checkpoint callback\n",
    "checkpoint_callback_6 = ModelCheckpoint('best_model_6.keras', \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True, \n",
    "                                      mode='min', \n",
    "                                      verbose=1)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', \n",
    "                                       patience=3, \n",
    "                                       mode='min', \n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "# # instantiating the model in the strategy scope creates the model on the TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras import Input, Model\n",
    "import keras\n",
    "# Define parameters\n",
    "vocab_size = len(char_to_index)  # Size of vocabulary (unique characters)\n",
    "embedding_dim = 50  # Dimension of character embeddings\n",
    "lstm_units = 256  # Number of units in LSTM layers\n",
    "num_layers = 3  # Number of BiLSTM layers\n",
    "dropout_rate = 0.1  # Dropout rate\n",
    "\n",
    "# Custom Attention Layer\n",
    "@keras.saving.register_keras_serializable()\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        et = tf.squeeze(tf.tanh(tf.matmul(x, self.W) + self.b), axis=-1)\n",
    "        at = tf.nn.softmax(et)\n",
    "        at = tf.expand_dims(at, axis=-1)\n",
    "        output = x * at\n",
    "        return tf.reduce_sum(output, axis=1)\n",
    "\n",
    "# Define Sequential model\n",
    "model_6 = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model_6.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length_3))\n",
    "\n",
    "# Add BiLSTM layers with Dropout\n",
    "for _ in range(num_layers):\n",
    "    model_6.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True)))\n",
    "    model_6.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "# Add Attention Layer\n",
    "model_6.add(AttentionLayer())\n",
    "\n",
    "# Output layer\n",
    "model_6.add(Dense(units=vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T16:38:44.784991Z",
     "iopub.status.busy": "2024-06-22T16:38:44.784617Z",
     "iopub.status.idle": "2024-06-22T17:09:52.306418Z",
     "shell.execute_reply": "2024-06-22T17:09:52.305393Z",
     "shell.execute_reply.started": "2024-06-22T16:38:44.784961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3576 - loss: 2.0250\n",
      "Epoch 1: val_loss improved from inf to 1.46096, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 67ms/step - accuracy: 0.3576 - loss: 2.0249 - val_accuracy: 0.5023 - val_loss: 1.4610\n",
      "Epoch 2/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5176 - loss: 1.4068\n",
      "Epoch 2: val_loss improved from 1.46096 to 1.34231, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 68ms/step - accuracy: 0.5176 - loss: 1.4068 - val_accuracy: 0.5338 - val_loss: 1.3423\n",
      "Epoch 3/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5556 - loss: 1.2739\n",
      "Epoch 3: val_loss improved from 1.34231 to 1.29647, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 67ms/step - accuracy: 0.5556 - loss: 1.2739 - val_accuracy: 0.5456 - val_loss: 1.2965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78b0657f2e90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_6.fit( X_train_3, \n",
    "            y_train_3, \n",
    "            epochs=3, \n",
    "            batch_size=256, \n",
    "            validation_data=(X_val_3, y_val_3), \n",
    "            verbose=1,callbacks=[checkpoint_callback_6,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T17:10:01.762558Z",
     "iopub.status.busy": "2024-06-22T17:10:01.761742Z",
     "iopub.status.idle": "2024-06-22T18:22:08.163803Z",
     "shell.execute_reply": "2024-06-22T18:22:08.162930Z",
     "shell.execute_reply.started": "2024-06-22T17:10:01.762517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5770 - loss: 1.2009\n",
      "Epoch 1: val_loss improved from 1.29647 to 1.26940, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 67ms/step - accuracy: 0.5770 - loss: 1.2009 - val_accuracy: 0.5522 - val_loss: 1.2694\n",
      "Epoch 2/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5918 - loss: 1.1516\n",
      "Epoch 2: val_loss improved from 1.26940 to 1.26491, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 67ms/step - accuracy: 0.5918 - loss: 1.1516 - val_accuracy: 0.5558 - val_loss: 1.2649\n",
      "Epoch 3/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6027 - loss: 1.1156\n",
      "Epoch 3: val_loss improved from 1.26491 to 1.25808, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 67ms/step - accuracy: 0.6027 - loss: 1.1156 - val_accuracy: 0.5575 - val_loss: 1.2581\n",
      "Epoch 4/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6109 - loss: 1.0910\n",
      "Epoch 4: val_loss improved from 1.25808 to 1.25142, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 67ms/step - accuracy: 0.6109 - loss: 1.0910 - val_accuracy: 0.5579 - val_loss: 1.2514\n",
      "Epoch 5/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6179 - loss: 1.0693\n",
      "Epoch 5: val_loss improved from 1.25142 to 1.24678, saving model to best_model_6.keras\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 67ms/step - accuracy: 0.6179 - loss: 1.0693 - val_accuracy: 0.5600 - val_loss: 1.2468\n",
      "Epoch 6/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6221 - loss: 1.0548\n",
      "Epoch 6: val_loss did not improve from 1.24678\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 67ms/step - accuracy: 0.6221 - loss: 1.0548 - val_accuracy: 0.5597 - val_loss: 1.2529\n",
      "Epoch 7/7\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6271 - loss: 1.0404\n",
      "Epoch 7: val_loss did not improve from 1.24678\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 67ms/step - accuracy: 0.6271 - loss: 1.0404 - val_accuracy: 0.5599 - val_loss: 1.2528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78b0657f24a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_6.fit( X_train_3, \n",
    "            y_train_3, \n",
    "            epochs=7, \n",
    "            batch_size=256, \n",
    "            validation_data=(X_val_3, y_val_3), \n",
    "            verbose=1,callbacks=[checkpoint_callback_6,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T03:42:37.872300Z",
     "iopub.status.busy": "2024-06-23T03:42:37.871942Z",
     "iopub.status.idle": "2024-06-23T03:42:37.876581Z",
     "shell.execute_reply": "2024-06-23T03:42:37.875575Z",
     "shell.execute_reply.started": "2024-06-23T03:42:37.872273Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint_callback_total6 = ModelCheckpoint('best_model_6.keras', \n",
    "#                                       monitor='val_loss', \n",
    "#                                       save_best_only=True, \n",
    "#                                       mode='min', \n",
    "#                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T18:22:30.320282Z",
     "iopub.status.busy": "2024-06-22T18:22:30.319930Z",
     "iopub.status.idle": "2024-06-22T18:53:42.400754Z",
     "shell.execute_reply": "2024-06-22T18:53:42.399846Z",
     "shell.execute_reply.started": "2024-06-22T18:22:30.320253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6297 - loss: 1.0308\n",
      "Epoch 1: val_loss did not improve from 1.24678\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 68ms/step - accuracy: 0.6297 - loss: 1.0308 - val_accuracy: 0.5604 - val_loss: 1.2492\n",
      "Epoch 2/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6336 - loss: 1.0203\n",
      "Epoch 2: val_loss did not improve from 1.24678\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 68ms/step - accuracy: 0.6336 - loss: 1.0203 - val_accuracy: 0.5600 - val_loss: 1.2582\n",
      "Epoch 3/3\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6364 - loss: 1.0107\n",
      "Epoch 3: val_loss did not improve from 1.24678\n",
      "\u001b[1m9194/9194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 67ms/step - accuracy: 0.6364 - loss: 1.0107 - val_accuracy: 0.5600 - val_loss: 1.2575\n",
      "Epoch 3: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78b0657f3c10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_6.fit(X_train_3, \n",
    "            y_train_3, \n",
    "            epochs=3,      \n",
    "            batch_size=256,                     \n",
    "            validation_data=(X_val_3, y_val_3), \n",
    "            verbose=1,\n",
    "            callbacks=[checkpoint_callback_6,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Training data\n",
    "# randome shuffling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:45:14.938104Z",
     "iopub.status.busy": "2024-06-23T06:45:14.937533Z",
     "iopub.status.idle": "2024-06-23T06:45:15.021691Z",
     "shell.execute_reply": "2024-06-23T06:45:15.020885Z",
     "shell.execute_reply.started": "2024-06-23T06:45:14.938073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_2               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_2               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate, Layer\n",
    "from tensorflow.keras import Input, Model\n",
    "import keras\n",
    "# Define parameters\n",
    "vocab_size = len(char_to_index)  # Size of vocabulary (unique characters)\n",
    "embedding_dim = 50  # Dimension of character embeddings\n",
    "lstm_units = 256  # Number of units in LSTM layers\n",
    "num_layers = 3  # Number of BiLSTM layers\n",
    "dropout_rate = 0.1  # Dropout rate\n",
    "\n",
    "# Custom Attention Layer\n",
    "@keras.saving.register_keras_serializable()\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        et = tf.squeeze(tf.tanh(tf.matmul(x, self.W) + self.b), axis=-1)\n",
    "        at = tf.nn.softmax(et)\n",
    "        at = tf.expand_dims(at, axis=-1)\n",
    "        output = x * at\n",
    "        return tf.reduce_sum(output, axis=1)\n",
    "\n",
    "# Define Sequential model\n",
    "model_complete_6 = Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model_complete_6.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length_3))\n",
    "\n",
    "# Add BiLSTM layers with Dropout\n",
    "for _ in range(num_layers):\n",
    "    model_complete_6.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True)))\n",
    "    model_complete_6.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "# Add Attention Layer\n",
    "model_complete_6.add(AttentionLayer())\n",
    "\n",
    "# Output layer\n",
    "model_complete_6.add(Dense(units=vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_complete_6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_complete_6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:42:52.358979Z",
     "iopub.status.busy": "2024-06-23T04:42:52.358630Z",
     "iopub.status.idle": "2024-06-23T06:33:12.074738Z",
     "shell.execute_reply": "2024-06-23T06:33:12.073859Z",
     "shell.execute_reply.started": "2024-06-23T04:42:52.358947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 63ms/step - accuracy: 0.3843 - loss: 1.9180\n",
      "Epoch 2/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m823s\u001b[0m 63ms/step - accuracy: 0.5356 - loss: 1.3418\n",
      "Epoch 3/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 63ms/step - accuracy: 0.5648 - loss: 1.2346\n",
      "Epoch 4/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 63ms/step - accuracy: 0.5810 - loss: 1.1759\n",
      "Epoch 5/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 63ms/step - accuracy: 0.5912 - loss: 1.1411\n",
      "Epoch 6/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 63ms/step - accuracy: 0.5983 - loss: 1.1167\n",
      "Epoch 7/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 63ms/step - accuracy: 0.6037 - loss: 1.0979\n",
      "Epoch 8/8\n",
      "\u001b[1m13135/13135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 63ms/step - accuracy: 0.6080 - loss: 1.0840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e550bbfac80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train_complete_3, y_train_complete_3 = shuffle( X_padded_3, y_padded_3 )\n",
    "\n",
    "# Train the model\n",
    "model_complete_6.fit( X_train_complete_3, \n",
    "            y_train_complete_3,\n",
    "            epochs=8, \n",
    "            batch_size=256, \n",
    "#             validation_data=(X_val_3, y_val_3), \n",
    "            verbose=1,\n",
    "#             callbacks=[checkpoint_callback_6,early_stopping_callback]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:34:06.411147Z",
     "iopub.status.busy": "2024-06-23T06:34:06.410829Z",
     "iopub.status.idle": "2024-06-23T06:34:06.597040Z",
     "shell.execute_reply": "2024-06-23T06:34:06.596263Z",
     "shell.execute_reply.started": "2024-06-23T06:34:06.411121Z"
    }
   },
   "outputs": [],
   "source": [
    "model_complete_6.save('best_model_6_complete.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complete_6_recon = tf.keras.models.load_model('best_model_6_complete.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:34:29.785724Z",
     "iopub.status.busy": "2024-06-23T06:34:29.785368Z",
     "iopub.status.idle": "2024-06-23T06:34:29.789851Z",
     "shell.execute_reply": "2024-06-23T06:34:29.788969Z",
     "shell.execute_reply.started": "2024-06-23T06:34:29.785697Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_complete_6_recon = tf.keras.models.load_model('best_model_6_complete.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:34:46.128679Z",
     "iopub.status.busy": "2024-06-23T06:34:46.128022Z",
     "iopub.status.idle": "2024-06-23T06:34:46.132463Z",
     "shell.execute_reply": "2024-06-23T06:34:46.131430Z",
     "shell.execute_reply.started": "2024-06-23T06:34:46.128647Z"
    }
   },
   "outputs": [],
   "source": [
    "## load model \n",
    "# model_6_recon = tf.keras.models.load_model('best_model_6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T06:46:27.205229Z",
     "iopub.status.busy": "2024-06-23T06:46:27.204167Z",
     "iopub.status.idle": "2024-06-23T06:48:44.075491Z",
     "shell.execute_reply": "2024-06-23T06:48:44.074622Z",
     "shell.execute_reply.started": "2024-06-23T06:46:27.205177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15762/15762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.6346 - loss: 1.0046\n",
      "validation set Accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "loss, accuracy = model_complete_6_recon.evaluate(X_test_3, y_test_3, verbose=1)\n",
    "print(f\"validation set Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T20:09:32.251564Z",
     "iopub.status.busy": "2024-06-22T20:09:32.250964Z",
     "iopub.status.idle": "2024-06-22T20:11:47.163628Z",
     "shell.execute_reply": "2024-06-22T20:11:47.162754Z",
     "shell.execute_reply.started": "2024-06-22T20:09:32.251534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15762/15762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 8ms/step - accuracy: 0.5564 - loss: 1.2554\n",
      "validation set Accuracy: 55.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "loss, accuracy = model_6_recon.evaluate(X_test_3, y_test_3, verbose=1)\n",
    "print(f\"validation set Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5241531,
     "sourceId": 8732277,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5261218,
     "sourceId": 8757543,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5262822,
     "sourceId": 8759694,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5262852,
     "sourceId": 8759733,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 184902460,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
